{
  "project_id": "frontdoor-apisix",
  "project_name": "AI Front Door with APISIX Gateway",
  "version": "1.0.0",
  "description": "AI Front Door service with APISIX API Gateway for intelligent routing, authentication, and rate limiting",
  "owner": "AI-Platform-Team",
  "team": [
    "platform@company.com",
    "devops@company.com"
  ],
  "tags": [
    "ai-gateway",
    "apisix",
    "production",
    "llm-routing"
  ],
  "environment": "production",
  "created_at": "2025-09-24T17:50:00",
  "updated_at": "2025-09-24T17:50:00",
  "modules": [
    {
      "module_type": "jwt_config",
      "name": "jwt-auth-service",
      "version": "1.0.0",
      "status": "enabled",
      "description": "JWT authentication service for API access",
      "dependencies": [],
      "cross_references": {},
      "environment_overrides": {
        "development": {
          "expiration_minutes": 60
        },
        "production": {
          "expiration_minutes": 15
        }
      },
      "config": {
        "secret_key": "${JWT_SECRET_KEY}",
        "algorithm": "RS256",
        "expiration_minutes": 30,
        "issuer": "frontdoor-ai-gateway",
        "audience": "ai-services",
        "refresh_token_enabled": true
      }
    },
    {
      "module_type": "api_gateway",
      "name": "apisix-gateway",
      "version": "1.0.0",
      "status": "enabled",
      "description": "APISIX API Gateway for AI service routing and management",
      "dependencies": ["jwt-auth-service"],
      "cross_references": {
        "auth_service": {
          "module_name": "jwt-auth-service",
          "module_type": "jwt_config",
          "purpose": "JWT token validation for API requests",
          "required": true
        },
        "llm_service": {
          "module_name": "llm-inference-cluster",
          "module_type": "inference_endpoint",
          "purpose": "Route to LLM inference endpoints",
          "required": true
        }
      },
      "environment_overrides": {},
      "config": {
        "admin_api_url": "http://apisix:9180",
        "admin_key": "${APISIX_ADMIN_KEY}",
        "gateway_url": "http://apisix:9080",
        "dashboard_url": "http://apisix-dashboard:9000",
        "routes": [
          {
            "name": "llm-inference-route",
            "uri": "/v1/inference/*",
            "methods": ["POST", "GET", "OPTIONS"],
            "upstream_id": "llm-upstream",
            "plugins": [
              {
                "name": "jwt-auth",
                "enabled": true,
                "config": {
                  "key": "user-key",
                  "secret": "${JWT_SECRET_KEY}",
                  "algorithm": "RS256",
                  "exp": 3600,
                  "header": "Authorization",
                  "cookie": "jwt_token",
                  "hide_credentials": true
                },
                "priority": 1000
              },
              {
                "name": "limit-req",
                "enabled": true,
                "config": {
                  "rate": 100,
                  "burst": 50,
                  "rejected_code": 429,
                  "key_type": "var",
                  "key": "remote_addr",
                  "rejected_msg": "Rate limit exceeded. Please try again later."
                },
                "priority": 900
              },
              {
                "name": "limit-count",
                "enabled": true,
                "config": {
                  "count": 1000,
                  "time_window": 3600,
                  "key_type": "var",
                  "key": "consumer_name",
                  "policy": "local",
                  "rejected_code": 429,
                  "rejected_msg": "API quota exceeded for this hour."
                },
                "priority": 850
              },
              {
                "name": "prometheus",
                "enabled": true,
                "config": {
                  "prefer_name": true
                },
                "priority": 800
              },
              {
                "name": "request-id",
                "enabled": true,
                "config": {
                  "header_name": "X-Request-Id",
                  "include_in_response": true,
                  "algorithm": "uuid"
                },
                "priority": 750
              },
              {
                "name": "http-logger",
                "enabled": true,
                "config": {
                  "uri": "http://logging-service:8080/logs",
                  "batch_max_size": 1000,
                  "inactive_timeout": 5,
                  "buffer_duration": 60,
                  "max_retry_count": 3,
                  "retry_delay": 1,
                  "include_req_body": true,
                  "include_resp_body": false,
                  "include_req_body_expr": [
                    ["arg_log_body", "==", "true"]
                  ]
                },
                "priority": 700
              },
              {
                "name": "proxy-rewrite",
                "enabled": true,
                "config": {
                  "regex_uri": ["^/v1/inference/(.*)", "/$1"],
                  "headers": {
                    "X-Gateway-Version": "1.0.0",
                    "X-Forwarded-Service": "apisix-gateway"
                  }
                },
                "priority": 600
              },
              {
                "name": "response-rewrite",
                "enabled": false,
                "config": {
                  "headers": {
                    "X-Powered-By": "APISIX AI Gateway",
                    "X-Response-Time": "$upstream_response_time"
                  }
                },
                "priority": 500
              }
            ]
          },
          {
            "name": "health-check-route",
            "uri": "/health",
            "methods": ["GET"],
            "plugins": [
              {
                "name": "serverless-pre-function",
                "enabled": true,
                "config": {
                  "phase": "access",
                  "functions": [
                    "return function(conf, ctx) ngx.say('{\"status\":\"healthy\",\"service\":\"apisix-gateway\"}') ngx.exit(200) end"
                  ]
                }
              }
            ],
            "priority": 100
          },
          {
            "name": "metrics-route",
            "uri": "/metrics",
            "methods": ["GET"],
            "plugins": [
              {
                "name": "public-api",
                "enabled": true,
                "config": {}
              }
            ],
            "priority": 90
          }
        ],
        "upstreams": [
          {
            "name": "llm-upstream",
            "type": "roundrobin",
            "nodes": {
              "llm-service-1:8080": 100,
              "llm-service-2:8080": 100,
              "llm-service-3:8080": 100
            },
            "timeout": {
              "connect": 10,
              "send": 60,
              "read": 300
            },
            "retries": 2,
            "health_check": {
              "active": {
                "type": "http",
                "http_path": "/health",
                "healthy": {
                  "interval": 2,
                  "successes": 2
                },
                "unhealthy": {
                  "interval": 1,
                  "http_failures": 2
                }
              }
            }
          }
        ],
        "global_plugins": [
          {
            "name": "cors",
            "enabled": true,
            "config": {
              "allow_origins": "${CORS_ORIGINS}",
              "allow_methods": "GET, POST, PUT, DELETE, OPTIONS, HEAD, PATCH",
              "allow_headers": "*",
              "expose_headers": "X-Request-Id, X-RateLimit-Limit, X-RateLimit-Remaining",
              "allow_credential": true,
              "max_age": 3600
            },
            "priority": 5000
          },
          {
            "name": "real-ip",
            "enabled": true,
            "config": {
              "source": "http_x_forwarded_for",
              "trusted_addresses": ["10.0.0.0/8", "172.16.0.0/12", "192.168.0.0/16"]
            },
            "priority": 4000
          },
          {
            "name": "gzip",
            "enabled": true,
            "config": {
              "types": ["text/plain", "text/html", "application/json"],
              "min_length": 1024,
              "comp_level": 6
            },
            "priority": 3000
          }
        ],
        "jwt_auth_enabled": true,
        "rate_limiting_enabled": true,
        "logging_enabled": true,
        "prometheus_enabled": true,
        "ssl_enabled": false,
        "cors_enabled": true,
        "cors_origins": ["*"],
        "cors_methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "default_timeout": 300,
        "default_retries": 2,
        "streaming_enabled": true,
        "response_buffering": false,
        "request_buffering": true
      }
    },
    {
      "module_type": "inference_endpoint",
      "name": "llm-inference-cluster",
      "version": "1.0.0",
      "status": "enabled",
      "description": "LLM inference endpoint cluster",
      "dependencies": ["apisix-gateway"],
      "cross_references": {
        "gateway": {
          "module_name": "apisix-gateway",
          "module_type": "api_gateway",
          "purpose": "Receive routed requests from gateway",
          "required": true
        }
      },
      "environment_overrides": {},
      "config": {
        "model_name": "${LLM_MODEL_NAME}",
        "model_version": "latest",
        "endpoint_url": "http://llm-service:8080/v1/completions",
        "system_prompt": "You are a helpful AI assistant. Provide accurate and helpful responses.",
        "max_tokens": 4096,
        "temperature": 0.7,
        "top_p": 0.9,
        "batch_size": 1
      }
    },
    {
      "module_type": "monitoring",
      "name": "observability-stack",
      "version": "1.0.0",
      "status": "enabled",
      "description": "Monitoring and observability for APISIX gateway",
      "dependencies": ["apisix-gateway"],
      "cross_references": {
        "gateway": {
          "module_name": "apisix-gateway",
          "module_type": "api_gateway",
          "purpose": "Collect metrics and logs from gateway",
          "required": true
        }
      },
      "environment_overrides": {},
      "config": {
        "metrics_enabled": true,
        "logging_level": "INFO",
        "tracing_enabled": true,
        "health_check_interval": 30,
        "alerting_enabled": true,
        "dashboard_url": "http://grafana:3000"
      }
    },
    {
      "module_type": "security",
      "name": "security-policies",
      "version": "1.0.0",
      "status": "enabled",
      "description": "Security policies and compliance for AI gateway",
      "dependencies": ["apisix-gateway", "jwt-auth-service"],
      "cross_references": {
        "gateway": {
          "module_name": "apisix-gateway",
          "module_type": "api_gateway",
          "purpose": "Apply security policies to gateway",
          "required": true
        },
        "auth": {
          "module_name": "jwt-auth-service",
          "module_type": "jwt_config",
          "purpose": "Token validation and authorization",
          "required": true
        }
      },
      "environment_overrides": {},
      "config": {
        "encryption_at_rest": true,
        "encryption_in_transit": true,
        "vulnerability_scanning": true,
        "access_control_type": "rbac",
        "audit_logging": true,
        "compliance_standards": ["SOC2", "ISO27001"]
      }
    }
  ],
  "metadata": {
    "cost_center": "AI-Platform",
    "business_unit": "Engineering",
    "compliance_level": "high",
    "data_classification": "sensitive",
    "support_contact": "ai-platform@company.com",
    "docker_compose_file": "./docker-compose.yml",
    "apisix_config_dir": "./apisix-config",
    "deployment_notes": "APISIX runs as a Docker container with exposed ports 9080 (gateway) and 9180 (admin API)"
  }
}
